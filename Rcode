---
title: "PSTAT 126 Regression Analysis - Political Poll Donations - Appendix"
author: Elisa Cui & Sam O'neill
date: 3/18/2018
output: pdf_document
---

\pagenumbering{gobble}

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=6, fig.height=4,eval=FALSE)

#install.packages("Quandl")
library(Quandl)
library (knitr)
library (dplyr)
library (plyr)
library (tidyverse)
library (tree)
library (randomForest)
library (gbm)
library (ROCR)
library (e1071)
library (imager)
library (ISLR)
library(reshape2)
library(class)
# install.packages("lattice")
library(lattice)
library(Hmisc)

setwd(dir = "/Users/SamONeill/Documents/UCSB/UCSB_2017-2018/PSTAT 231/Final Project/")
# dow.jones = read.table("dow_jones_index.data",sep=",", na.strings = c("","NA"),header=T,stringsAsFactors=FALSE)
# dow.jones <- dow.jones %>% mutate substring(dow.jones$high,2)

sp_data <- read_csv("sp_data.csv")
actualDates=sp_data$Date
#Date: Months from start date 
sp_data <- sp_data %>% mutate(Date = 1:nrow(sp_data))
sp_data$monthly_price_change <- NA

for (i in 1:nrow(sp_data)){
  sp_data$monthly_price_change[i] <- (sp_data$`Real Price`[i+1] - 
                                        sp_data$`Real Price`[i])/(sp_data$`Real Price`[i])
}

sp_data <- filter(sp_data, complete.cases(sp_data));

sp_data <- sp_data %>%
  mutate(monthly_price_change_dir =
  as.factor(ifelse(sp_data$monthly_price_change>0,"Increase","Decrease")))

#create training and test data
set.seed(1)
#get rid of unhelpful columns
data=sp_data %>% dplyr::select(-c(SP500,Dividend,Earnings,monthly_price_change))
colnames(data) <- c("Date","CPI","lit","real_price","real_div",
                    "real_earnings","pe10","monthly_price_change_dir")
data.scaled=scale(as.data.frame(data[1:ncol(data)-1]))
data.scaled=as.tibble(data.scaled) %>% 
  mutate(monthly_price_change_dir=data$monthly_price_change_dir)
#data=data.scaled

test.frac=.95
train.indices=sample(1:nrow(data),floor(test.frac*nrow(data)))
data.train=data[1:floor(test.frac*nrow(data)),]
data.test=data[ceiling(test.frac*nrow(data)):nrow(data),]

train_labels=data.train$monthly_price_change_dir
train_predictors=data.train[,-ncol(data.train)]

test_labels=data.test$monthly_price_change_dir
test_predictors=data.test[,-ncol(data.test)]
```

```{r data}
#DATA SETUP
#-----------------------------------------------------------------------------
sp_data <- read_csv("sp_data.csv")
actualDates=sp_data$Date
#Date: Months from start date 
sp_data <- sp_data %>% mutate(Date = 1:nrow(sp_data))
sp_data$monthly_price_change <- NA

for (i in 1:nrow(sp_data)){
  sp_data$monthly_price_change[i] <- (sp_data$`Real Price`[i+1] - 
                                      sp_data$`Real Price`[i])/(sp_data$`Real Price`[i])
}

sp_data <- filter(sp_data, complete.cases(sp_data));

sp_data <- sp_data %>% 
  mutate(monthly_price_change_dir =
  as.factor(ifelse(sp_data$monthly_price_change>0,"Increase","Decrease")))

#create training and test data
set.seed(1)
#get rid of unhelpful columns
data=sp_data %>% dplyr::select(-c(SP500,Dividend,Earnings,monthly_price_change))
colnames(data) <- c("Date","CPI","lit","real_price","real_div",
                    "real_earnings","pe10","monthly_price_change_dir")
data.scaled=scale(as.data.frame(data[1:ncol(data)-1]))
data.scaled=as.tibble(data.scaled) %>% 
  mutate(monthly_price_change_dir=data$monthly_price_change_dir)
#data=data.scaled

test.frac=.95
train.indices=sample(1:nrow(data),floor(test.frac*nrow(data)))
data.train=data[1:floor(test.frac*nrow(data)),]
data.test=data[ceiling(test.frac*nrow(data)):nrow(data),]

train_labels=data.train$monthly_price_change_dir
train_predictors=data.train[,-ncol(data.train)]

test_labels=data.test$monthly_price_change_dir
test_predictors=data.test[,-ncol(data.test)]
#-----------------------------------------------------------------------------
```



```{r pca}
#PRINCIPAL COMPONENT ANALYSIS
#-----------------------------------------------------------------------------
predictors=data[-ncol(data)]
pr.out=prcomp(predictors, scale=TRUE,center = TRUE)
pr.var=pr.out$sdev ^2
pve=pr.var/sum(pr.var)
plot(pve, xlab="Principal Component", 
     ylab="Proportion of Variance Explained ", ylim=c(0,1),type='b')

plot(cumsum(pve), xlab="Principal Component ", 
     ylab=" Cumulative Proportion of Variance Explained ", ylim=c(0,1), type='b')

pr.out$rotation

rainbow_colors <- rainbow(2)
plot_colors <- rainbow_colors[data$monthly_price_change_dir]
plot.range=1:1623
xlim=c(-2,4)
#plot PC1 v PC2
PC1_vals=pr.out$x[plot.range,1]
PC2_vals=pr.out$x[plot.range,2]
min=min(PC1_vals,PC2_vals)-2
plot(PC1_vals,PC2_vals,col=plot_colors,cex=.6,xlab="PC1",ylab="PC2",
     main="Data Plotted w/ 1st and 2rd Principal Components",
     ylim=c(min,4))
legend("bottomright", c("Increase","Decrease"),
  	fill=c("Blue","Red"), 
  	cex=.8,horiz=TRUE,inset=.02)
#plot PC1 v PC3
PC1_vals=pr.out$x[plot.range,1]
PC3_vals=pr.out$x[plot.range,3]
min=min(PC1_vals,PC3_vals)-2
plot(PC1_vals,PC3_vals,col=plot_colors,cex=.6,xlab="PC1",ylab="PC3",
     main="Data Plotted w/ 1st and 3rd Principal Components",
     ylim=c(min,4))
legend("bottomright", c("Increase","Decrease"),
  	fill=c("Blue","Red"), 
  	cex=.8,horiz=TRUE,inset=.02)
#plot PC2 v PC3
min=min(PC2_vals,PC3_vals)-2
plot(PC2_vals,PC3_vals,col=plot_colors,cex=.6,xlab="PC2",ylab="PC3",
     main="Data Plotted w/ 2nd and 3rd Principal Components",
     ylim=c(min,4))
legend("bottomright", c("Increase","Decrease"),
  	fill=c("Blue","Red"), 
  	cex=.8,horiz=TRUE,inset=.02)
#-----------------------------------------------------------------------------
```


```{r hclust}
#HIERARCHICAL CLUSTERING
#-----------------------------------------------------------------------------
s.predictors=scale(predictors)
d=dist(s.predictors)
#AVERAGE LINKAGE
hc=hclust(d,method="average")

clus = cutree(hc, 7)
table(clus)

#Heatmap plot
levelplot(as.matrix(d)[hc$order,hc$order],
          at=pretty(c(0, 10), n=10),
          scale(tick.number=1,draw=FALSE),
          scales=list(y=list(cex=.01),x=list(cex=.01)),
          main="Heat Map of Stock Data",
          xlab="Data Ordered by Hierarchical Clustering",
          ylab="")
      

data$Date[hc$order][1400:1600]
#-----------------------------------------------------------------------------
```


```{r knn}
#K-NEAREST NEIGHBORS MODEL DEVELOPMENT
#-----------------------------------------------------------------------------
#perform cross-validation to find best k to be used in knn model
calc_error_rate <- function(predicted.value, true.value){
  return(mean(true.value!=predicted.value))
}

nfold = 10
set.seed(1)
folds = seq.int(nrow(data.train)) %>%
        cut(breaks = nfold, labels=FALSE) %>% 
        sample
kvec=c(1,seq(10,50,length.out=5))
# do.chunk() for k-fold Cross-validation
do.chunk <- function(chunkid, folddef, Xdat, Ydat, k){ 
  train = (folddef!=chunkid)
  Xtr = Xdat[train,]
  Ytr = Ydat[train]
  
  Xvl = Xdat[!train,] 
  Yvl = Ydat[!train]
  ## get classifications for current training chunks 
  predYtr = knn(train = Xtr, test = Xtr, cl = Ytr, k = k)

  ## get classifications for current test chunk
  predYvl = knn(train = Xtr, test = Xvl, cl = Ytr, k = k)
  data.frame(train.error = calc_error_rate(predYtr, Ytr), 
             val.error = calc_error_rate(predYvl, Yvl))
}

mean_test_errors <- c()
mean_train_errors <- c()
for(i in kvec){
  poly_cv_10fold_errors <- lapply(c(1,2,3,4,5,6,7,8,9,10),
                                 do.chunk,folddef=folds,k=i,
                                 Xdat=train_predictors,Ydat=train_labels)
  mean_test_errors <- c(mean_test_errors,
                        mean(sapply(poly_cv_10fold_errors,function(X) X$val.error)))
  mean_train_errors <- c(mean_train_errors, 
                         mean(sapply(poly_cv_10fold_errors,function(X) X$train.error)))
}

plot_matrix=cbind(k=kvec,mean_train_errors,mean_test_errors)
plot_matrix=as_tibble(plot_matrix)
ggplot(plot_matrix,aes(x=kvec))+
  geom_line(aes(y=mean_train_errors,colour="Mean Train Errors"))+
  geom_line(aes(y=mean_test_errors,colour="Mean Test Errors"))+
  ylab("Mean Squared Error")+ xlab("k (# of neighbors)")+
  ggtitle("KNN Cross-Validation")

bestk.knn=kvec[which.min(mean_test_errors)]
```

```{r knn2}
prob_test_knn=knn(train = train_predictors, test = test_predictors,
                  cl = train_labels, k = bestk.knn, prob=TRUE)
prob_test_knn=attr(prob_test_knn, "prob")
pred_knn = prediction(prob_test_knn, test_labels)
perf_knn = performance(pred_knn, measure="tpr",x.measure="fpr")

#-----------------------------------------------------------------------------
```



```{r logistic}
#LOGISTIC REGRESSION MODEL DEVELOPMENT
#-----------------------------------------------------------------------------
log.reg = glm(monthly_price_change_dir~.,data=data.train, family=binomial)
#summary(log.reg)

prob_test_logistic = predict(log.reg, test_predictors, type="response")
#roc curve values for logistic regression model
pred_logistic = prediction(prob_test_logistic, test_labels)
perf_logistic = performance(pred_logistic, measure="tpr",x.measure="fpr")
#-----------------------------------------------------------------------------
```


```{r dectree}
#DECISION TREE MODEL DEVELOPMENT
#-----------------------------------------------------------------------------
tree_parameters=tree.control(nobs=nrow(data.train),minsize=10,mindev=1e-3)
stock.dec.tree=tree(monthly_price_change_dir~.,
                    data=data.train,control=tree_parameters)

#prune.tree method to find optimal tree size
prune = prune.tree(stock.dec.tree,
                   k = seq(from = 0, to = 100, by = .5), method = "misclass")
# Best size is 152
best.prune = prune$size[which.min(prune$dev)]

pruned_tree <- prune.tree(stock.dec.tree,best=best.prune,method="misclass")

prob_test_tree=predict(pruned_tree, test_predictors,type="vector")
#roc curve values for decision tree model
pred_tree = prediction(prob_test_tree[,2], test_labels)
perf_tree = performance(pred_tree, measure="tpr",x.measure="fpr")
#-----------------------------------------------------------------------------
```

```{r rf}
#RANDOM FOREST MODEL DEVELOPMENT
#-----------------------------------------------------------------------------
#random forest model
sp.rf <- randomForest(monthly_price_change_dir~., data=data.train, 
                      importance=TRUE,ntree=500)
print(sp.rf)

prob_test_rf=predict(sp.rf, test_predictors,type="prob")
pred_rf = prediction(prob_test_rf[,2], test_labels)
perf_rf = performance(pred_rf, measure="tpr",x.measure="fpr")
#-----------------------------------------------------------------------------
```

```{r boost}
#BOOSTED TREE MODEL DEVELOPMENT
#-----------------------------------------------------------------------------
set.seed(1)
boost.sp = gbm(ifelse(monthly_price_change_dir=="Increase",1,0)~., data=data.train, 
                     distribution="bernoulli", n.trees=1000, interaction.depth=1)

summary(boost.sp)

# par(mfrow =c(1,2))
# plot(boost.sp ,i="Date")

yhat.boost = predict(boost.sp, newdata = test_predictors,
                     type="response", n.trees=500)

# Confusion matrix w/ prob threshold = .5
boost.err = table(pred = ifelse(yhat.boost>=0.5, "Increase", "Decrease"),
                  truth = test_labels)
test.boost.err = 1 - sum(diag(boost.err))/sum(boost.err)
#test.boost.err

prob_test_boost=predict(boost.sp, test_predictors,type="link",n.trees=1000)
pred_boost = prediction(prob_test_boost, test_labels)
perf_boost = performance(pred_boost, measure="tpr",x.measure="fpr")
#-----------------------------------------------------------------------------
```

```{r svm 1,include=FALSE}
set.seed(1)
# tune.out=tune(svm,monthly_price_change_dir~.,data=data.train,kernel="radial",
#               ranges=list(cost=c(20000),
#                           gamma=c(0.5,1,2,3,4)))
# summary(tune.out)
# 
# best.cost=tune.out$best.parameters[1] %>% pull(1)
# best.gamma=tune.out$best.parameters[2] %>% pull(1)
# 
 svm.sp=svm(monthly_price_change_dir~., data=data.train,
           kernel="radial",gamma=1,cost=1000,
           probability=TRUE)

m <- matrix(0, ncol = nrow(data.train), nrow = 0)
pred.matrix=as_data_frame(m)
#add rows to matrix that contain predicted values of observations 
#from test set for each bootstrap
for(i in 1:200){
  set.seed(i)
  bootstrap=data.train[sample(1:nrow(data.train),nrow(data.train),replace=TRUE),]
  svm.fit=svm(monthly_price_change_dir~.,data=bootstrap,kernel="radial",cost=1000)
  yhat.svm=predict(svm.fit,data.test)
  pred.matrix=rbind(pred.matrix,yhat.svm)
}

prob.yes=apply(pred.matrix,2,function(c) sum(c==2)/200)

pred_svm = prediction(prob.yes, test_labels)
perf_svm = performance(pred_svm, measure="tpr",x.measure="fpr")
```


```{r roc}
#ROC CURVE COMPARISON
#-----------------------------------------------------------------------------
#get data ready to be used in ggplot
#for logistic
x_log=as.data.frame(perf_logistic@x.values,col.names ="x_log")
y_log=as.data.frame(perf_logistic@y.values,col.names ="y_log")
plot_log_df=cbind(x_log,y_log)
#for decision tree
x_tree=as.data.frame(perf_tree@x.values,col.names ="x_tree")
y_tree=as.data.frame(perf_tree@y.values,col.names ="y_tree")
plot_tree_df=cbind(x_tree,y_tree)
#for random forest
x_rf=as.data.frame(perf_rf@x.values,col.names ="x_rf")
y_rf=as.data.frame(perf_rf@y.values,col.names ="y_rf")
plot_rf_df=cbind(x_rf,y_rf)
#for boosted model
x_boost=as.data.frame(perf_rf@x.values,col.names ="x_boost")
y_boost=as.data.frame(perf_rf@y.values,col.names ="y_boost")
plot_boost_df=cbind(x_boost,y_boost)
#for knn model
x_knn=as.data.frame(perf_knn@x.values,col.names ="x_knn")
y_knn=as.data.frame(perf_knn@y.values,col.names ="y_knn")
plot_knn_df=cbind(x_knn,y_knn)

dividing_line <- data.frame(x=seq(from=0, to=1, by=0.1),y=seq(from=0, to=1, by=0.1))

ggplot(plot_log_df,aes(x=x_log))+geom_line(aes(y=y_log,colour="Logistic"))+
  geom_line(aes(x=x_tree,y=y_tree,colour="Decision Tree"),plot_tree_df)+
  geom_line(aes(x=x_rf,y=y_rf,colour="Random Forest"),plot_rf_df,lty=2,lwd=1.1)+
  geom_line(aes(x=x_boost,y=y_boost,colour="Boosted Tree"),plot_boost_df)+
  geom_line(aes(x=x_knn,y=y_knn,colour="knn"),plot_knn_df)+
  geom_line(aes(x=x,y=y),dividing_line)+
  ylab("True Positive Rate")+ xlab("False Positive Rate")+
  ggtitle("ROC Comparision")+
  theme_grey(base_size = 15)

log.auc = performance(pred_logistic, "auc")@y.values
print("logistic")
log.auc

tree.auc = performance(pred_tree, "auc")@y.values
print("tree")
tree.auc

rf.auc = performance(pred_rf, "auc")@y.values
print("random forest")
rf.auc

boost.auc = performance(pred_boost, "auc")@y.values
print("boost")
boost.auc

knn.auc = performance(pred_knn, "auc")@y.values
print("knn")
knn.auc
#-----------------------------------------------------------------------------
```

```{r bestp}
#FUNCTION TO FIND BEST PROBABILITY THRESHOLD BASED ON ROC CURVES
#-----------------------------------------------------------------------------
bestp <- function(perf,modeltype){
  fpr =perf@x.values[[1]]
  tpr = perf@y.values[[1]]
  cutoff = perf@alpha.values[[1]]
  rate = as.data.frame(cbind(Cutoff=cutoff, FPR=fpr, TPR=tpr))
  rate$distance = sqrt((rate[,2])^2+(1-rate[,3])^2)
  #minimizes fpr and fnr
  index = which.min(rate$distance)
  bestp = rate$Cutoff[index]
  c(bestp,modeltype)
}

# # Plot
# matplot(cutoff, cbind(fpr,tpr), type="l",lwd=2, xlab="Threshold",ylab="Error Rate")
# # Add legend to the plot
# legend(0.3, 1, legend=c("False Positive Rate","True Positive Rate"),
#        col=c(1,2), lty=c(1,2))
# # Plot
# matplot(cutoff, cbind(fpr,tpr), type="l",lwd=2, xlab="Threshold",ylab="Error Rate")
# # Add legend to the plot
# legend(0.35, 1, legend=c("False Positive Rate","False Negative Rate"),
#        col=c(1,2), lty=c(1,2))
# # Add the best value
# abline(v=bestp, col=3, lty=3, lwd=3)
#-----------------------------------------------------------------------------
```


```{r investment}
#STANDARD INVESTMENT STRATEGY SIMULATION
#-----------------------------------------------------------------------------
#make sure to reset bestp.parameters depending on which model is being used
#below are initial parameters that are set or given a range of values to loop over
bestp.parameters=bestp(perf_knn,"KNN")
p=as.numeric(bestp.parameters[1]) #probability threshold
modeltype=bestp.parameters[2]

sd=0 #initialize SD
seq.n=seq(20,220,40) #n to try
seq.frac.n=c(2,4,8) #frac.n to try
seq.start=seq(1500,1680,12) #start dates of time periods
forecast=60 #in months

#diff.adv.df1 stores average percent.adv for each parameter combination
diff.adv.df1=data_frame(n=numeric(1),frac.n=numeric(1),
                        ave.diff=numeric(1),ave.adv=numeric(1))

for(n in seq.n){
  for(frac.n in seq.frac.n){
    
differences=c()
advantage=c()
  
for(k in seq.start){
  start.time=k
  end.time=k+forecast
  #get actual index of start.time
  start=which(start.time==data$Date)
  money=1000*data$real_price[which(start.time==data$Date)]/100
  #start by buying 1000 "stocks" at price at t=start.time
  stock.value=0
  
  if(modeltype=="Logistic"){
  #gain idea of how pred.prob are distributed for logistic model
  log.reg=glm(monthly_price_change_dir~.,data=data[1:(start-50),], family=binomial)
  pred.probs=predict(log.reg,data[(start-49):start,],type="response")
  #use SD to weight buying and selling based on predictions
  sd=var(pred.probs)^.5
  }
  
for(i in start.time:(end.time-1)){
  j=which(i==data$Date)
  if(modeltype=="KNN"){
  #for knn (updated model each iteration based on previous data)
  pred.prob=knn(train = data[1:(j-1),-ncol(data)],
                test = data[j,-ncol(data)],
                cl = data$monthly_price_change_dir[1:(j-1)],
                k = bestk.knn, prob=TRUE)
  pred.prob=attr(pred.prob, "prob")
  }
  if(modeltype=="Logistic"){
  #for logistic (updated model each iteration based on previous data)
  log.reg = glm(monthly_price_change_dir~.,data=data[1:(j-1),], family=binomial)
  pred.prob=predict(log.reg, data[j,], type="response")
  }
  pred.change=ifelse(pred.prob>p,"Increase","Decrease")
  price.stocks=n*data$real_price[j]/100
  next.percent.change=(data$real_price[j+1]-data$real_price[j])/data$real_price[j]
  
  #if model predicts increase and we have enough money to buy n more stocks
  if(pred.change=="Increase" && money>price.stocks){
    if(modeltype=="Logistic"){
    #next 2 if clauses are used to weight stronger predictions with more buying/selling
    #if strongly predict increase
    if(pred.prob>(p+sd) && money>(frac.n/2*price.stocks)){
      price.stocks=frac.n/2*price.stocks #buy frac.n/2*n stocks instead of n
    }
    #if very strongly predict increase
    if(pred.prob>(p+1.98*sd) && money>(frac.n*price.stocks)){
      price.stocks=frac.n*price.stocks #buy frac.n*n stocks instead of n
    }
    }
    money=money-price.stocks #buy n stocks
    stock.value=stock.value+price.stocks 
    stock.value=stock.value*(1+next.percent.change)
  }
  #if model predicts decrease and we have enough stock value we sell n stocks
  else if(pred.change=="Decrease" && stock.value>price.stocks){
    if(modeltype=="Logistic"){
    #next 2 if clauses are used to weight stronger predictions with more buying/selling
    #if strongly predict decrease
    if(pred.prob<(p-sd) && stock.value>(frac.n/2*price.stocks)){
      price.stocks=frac.n/2*price.stocks #buy frac.n/2*n stocks instead of n
    }
     #if very strongly predict decrease
    if(pred.prob<(p-1.98*sd) && stock.value>(frac.n*price.stocks)){
      price.stocks=frac.n*price.stocks #buy frac.n*n stocks instead of n
    }
    }
    stock.value=stock.value-price.stocks #sell n stocks
    stock.value=stock.value*(1+next.percent.change)
    money=money+price.stocks
  }
  #if model predicts increase and we don't have enough money to buy n more stocks
  #we don't do anything
  else if(pred.change=="Increase" && money<=price.stocks){
    stock.value=stock.value*(1+next.percent.change)
  }
  #if model predicts decrease and we don't have enough money to sell n stocks
  #we don't do anything
  else if(pred.change=="Decrease" && stock.value<=price.stocks){
    stock.value=stock.value*(1+next.percent.change)
  }
  #print(money)
  #print(stock.value)
}
  netassets=money+stock.value
  #stock.value.normal is what one would get with long position
  stock.value.normal=1000*data$real_price[which(end.time==data$Date)]/100
  gain=netassets-stock.value.normal
  differences=c(differences,gain)
  percent.adv=gain/stock.value.normal*100
  advantage=c(advantage,percent.adv)
}

# print("ave money gained from initial investment")
# mean(differences)
# print("ave percent advantage over 5 years based on initial investment")
# mean(advantage)

row=c(n,frac.n,median(differences),median(advantage))
diff.adv.df1=rbind(diff.adv.df1,row)
  }
}

diff.adv.df1=diff.adv.df1[-1,]
#-----------------------------------------------------------------------------
```


```{r investmentVisualization,message=FALSE}
#STANDARD TRADING INVESTMENT VISUALIZATION CODE
#-----------------------------------------------------------------------------
#BEFORE RUNNING:
#reset bestp.parameters depending on model you want to use
#for example, for knn model, use bestp(perf_knn,"KNN")

#initial parameters that are set or given a range of values to loop over
bestp.parameters=bestp(perf_logistic,"Logistic")
p=as.numeric(bestp.parameters[1]) #probability threshold
modeltype=bestp.parameters[2]
sd=0 #initialize SD
#num stocks allowed to be bought/sold in investment strategy
n=40
#multiple of num stucks allowed to be bought/sold in case of strong prediction
frac.n=8
#based on data$Date column
start.time=1501
forecast=240
end.time=start.time+forecast
main=paste("Standard Trading Sim. w/ ",modeltype,toString(actualDates[start.time]),
  " to ",toString(actualDates[end.time]))

differences=c()
advantage=c()
total_assets=c()
stock_value=c()
money_series=c()
pred.changes=c()

#get actual index of start.time
start=which(start.time==data$Date)
money=1000*data$real_price[which(start.time==data$Date)]/100
#start by buying 1000 "stocks" at price at t=start.time
stock.value=0

num_truepos = 0; #count how many predicted increases are true
num_trueneg = 0 #count how many predicted decreases are true
num_falsepos = 0; #count how many predicted increases are false
num_falseneg = 0 #count how many predicted decreases are false

if(modeltype=="Logistic"){
#gain idea of how pred.prob are distributed for logistic model
log.reg=glm(monthly_price_change_dir~.,data=data[1:(start-50),], family=binomial)
pred.probs=predict(log.reg,data[(start-49):start,],type="response")
#use SD to weight buying and selling based on predictions
sd=var(pred.probs)^.5
}
  
stock_value=c(stock.value)
money_series=c(money)
total_assets=c(stock.value+money)
normal_assets=c(stock.value+money)
  
for(i in start.time:(end.time-1)){
  j=which(i==data$Date)
  
  if(modeltype=="KNN"){
  #for knn (updated model each iteration based on previous data)
  pred.prob=knn(train = data[1:(j-1),-ncol(data)],
                test = data[j,-ncol(data)],
                cl = data$monthly_price_change_dir[1:(j-1)],
                k = bestk.knn, prob=TRUE)
  pred.prob=attr(pred.prob, "prob")
  }
  
  if(modeltype=="Logistic"){
  #for logistic (updated model each iteration based on previous data)
  log.reg = glm(monthly_price_change_dir~.,data=data[1:(j-1),], family=binomial)
  pred.prob=predict(log.reg, data[j,], type="response")
  }
  
  pred.change=ifelse(pred.prob>p,"Increase","Decrease")
  pred.changes=c(pred.changes,pred.change)
  price.stocks=n*data$real_price[j]/100
  next.percent.change=(data$real_price[j+1]-data$real_price[j])/data$real_price[j]
  
  if(pred.change=="Increase" && next.percent.change>0){
    num_truepos=num_truepos+1
  }
  if(pred.change=="Decrease" && next.percent.change<0){
    num_trueneg=num_trueneg+1
  }
  if(pred.change=="Increase" && next.percent.change<0){
    num_falsepos=num_falsepos+1
  }
  if(pred.change=="Decrease" && next.percent.change>0){
    num_falseneg=num_falseneg+1
  }
  
  #if model predicts increase and we have enough money to buy n more stocks
  if(pred.change=="Increase" && money>price.stocks){
    if(modeltype=="Logistic"){
    ## next 2 if clauses are used to weight stronger predictions with more buying/selling
    #if strongly predict increase
    if(pred.prob>(p+sd) && money>(frac.n/2*price.stocks)){
      price.stocks=frac.n/2*price.stocks #buy frac.n/2*n stocks instead of n
    }
    #if very strongly predict increase
    if(pred.prob>(p+1.98*sd) && money>(frac.n*price.stocks)){
      price.stocks=frac.n*price.stocks #buy frac.n*n stocks instead of n
    }
    }
    money=money-price.stocks #buy n stocks
    stock.value=stock.value+price.stocks 
    stock.value=stock.value*(1+next.percent.change)
  }
  #if model predicts decrease and we have enough stock value we sell n stocks
  else if(pred.change=="Decrease" && stock.value>price.stocks){
    if(modeltype=="Logistic"){
    ##next 2 if clauses are used to weight stronger predictions with more buying/selling
    #if strongly predict decrease
    if(pred.prob<(p-sd) && stock.value>(frac.n/2*price.stocks)){
      price.stocks=frac.n/2*price.stocks #buy frac.n/2*n stocks instead of n
    }
     #if very strongly predict decrease
    if(pred.prob<(p-1.98*sd) && stock.value>(frac.n*price.stocks)){
      price.stocks=frac.n*price.stocks #buy frac.n*n stocks instead of n
    }
    }
    stock.value=stock.value-price.stocks #sell n stocks
    stock.value=stock.value*(1+next.percent.change)
    money=money+price.stocks
  }
  #if model predicts increase and we don't have enough money to buy n more stocks
  #we don't do anything
  else if(pred.change=="Increase" && money<=price.stocks){
    stock.value=stock.value*(1+next.percent.change)
  }
  #if model predicts decrease and we don't have enough money to sell n stocks
  #we don't do anything
  else if(pred.change=="Decrease" && stock.value<=price.stocks){
    stock.value=stock.value*(1+next.percent.change)
  }
  #print(money)
  #print(stock.value)
  stock_value=c(stock_value,stock.value)
  money_series=c(money_series,money)
  total_assets=c(total_assets,stock.value+money)
  normal_assets=c(normal_assets,
                  1000*data$real_price[j]/100)
}
  
netassets=money+stock.value
print("netassets")
print(netassets)
#without buying and selling
stock.value.normal=1000*data$real_price[which(end.time==data$Date)]/100
normal_assets=c(normal_assets,stock.value.normal)
print("stock.value.normal")
print(stock.value.normal)
gain=netassets-stock.value.normal
percent.adv=round(gain/stock.value.normal,3)*100
print("percent.adv")
print(percent.adv)
print("start date")
actualDates[start.time]
print("end date")
actualDates[end.time]
print("tpr")
print(num_truepos/(num_truepos+num_falsepos))
print("tnr")
print(num_trueneg/(num_trueneg+num_falseneg))


# print("ave money gained from initial investment")
# mean(differences)
# print("ave percent advantage over 5 years based on initial investment")
# mean(advantage)
max=max(normal_assets,total_assets)+4000
min=min(normal_assets,total_assets,money_series,stock_value)-4000

if(modeltype=="Logistic"){
  plotstring=paste("n=",toString(n),", frac.n=",toString(frac.n),
                   ", percent.adv=",toString(percent.adv),"%")
}
if(modeltype=="KNN"){
  plotstring=paste("n=",toString(n),", percent.adv=",toString(percent.adv),"%")
}

plot(1:(forecast+1),total_assets,col="red",
     ylim=c(min,max),
     ylab="Value ($)",xlab="Months",pch=1,
     main=main,cex=1)
     #main="Standard Trading Sim. w/ ** Model for Dates")
points(normal_assets,col="blue",pch=6)
points(money_series,col="orange",cex=.5,pch=3)
points(stock_value,col="green",cex=.5,pch=3)
legend("topleft",
  	c("Total Assets","Normal","Money","Stock Value"),
  	fill=c("red","blue","orange","green"), 
  	cex=.8,horiz=TRUE,inset=.02)
text(forecast/3, -3000, plotstring, cex = .8)
#-----------------------------------------------------------------------------
```


```{r shorting}
#SHORTING INVESTMENT STRATEGY SIMULATION
#-----------------------------------------------------------------------------
#make sure to reset bestp depending on which model is being used

#initial parameters that are set or given a range of values to loop over
bestp.parameters=bestp(perf_logistic,"Logistic")
p=as.numeric(bestp.parameters[1]) #probability threshold
modeltype=bestp.parameters[2]
sd=0 #initialize SD
seq.n=seq(20,220,40)

#For logistic regression only to make stronger decisions that increase volume of trade
seq.frac.n=seq(2,2,2)
#Seq values correspond to data$Date, not the row number
seq.start=seq(1500,1680,12)
forecast=60 #in months
margin = 0

diff.adv.df1=data_frame(n=numeric(1),frac.n=numeric(1),
                        ave.diff=numeric(1),ave.adv=numeric(1))

for(n in seq.n){
  for(frac.n in seq.frac.n){
    
differences=c()
advantage=c()
  
for(k in seq.start){
  start.time=k
  end.time=k+forecast
  #get actual index of start.time
  start=which(start.time==data$Date)
  
  num_shorts = 0;
  num_buybacks = 0
  
  bank=1000*data$real_price[which(start.time==data$Date)]
  oc_num_stocks =  1000

  #start by not shorting whatsoever
  num_stocks = 0;

for(i in start.time:(end.time-1)){
  j=which(i==data$Date)
  if(modeltype=="KNN"){
  # for knn (updated model each iteration based on previous data)
  pred.prob=knn(train = data[1:(j-1),-ncol(data)],
                test = data[j,-ncol(data)],
                cl = data$monthly_price_change_dir[1:(j-1)],
                k = bestk.knn, prob=TRUE)
  pred.prob=attr(pred.prob, "prob")
  }
  if(modeltype=="Logistic"){
  #for logistic (updated model each iteration based on previous data)
  log.reg = glm(monthly_price_change_dir~.,data=data[1:(j-1),], family=binomial)
  pred.prob=predict(log.reg, data[j,], type="response")
  }
  pred.change=ifelse(pred.prob>p,"Increase","Decrease")
  stocks.value=n*data$real_price[j]
  next.percent.change=(data$real_price[j+1]-data$real_price[j])/data$real_price[j]
  
  #if model predicts increase and we have enough money to buy n more stocks
  if(pred.change=="Increase" && bank>=stocks.value && num_stocks<=-n){
    bank=bank-stocks.value #buy n stocks
    num_stocks=num_stocks + n;
    num_buybacks = num_buybacks+1;
  }
  #if model predicts decrease and we have enough stock value we sell n stocks
  if(pred.change=="Decrease" && bank>=margin*stocks.value){
    num_stocks=num_stocks-n #short n stocks
    bank=bank+stocks.value
    num_shorts = num_shorts+1
  }
}
  netassets=bank+num_stocks*data$real_price[which(end.time==data$Date)]
  # print("net assets")
  # print(netassets)
  #without buying and selling
  oc_potential_gains=oc_num_stocks*data$real_price[which(end.time==data$Date)];
  # print(oc_potential_gains)
  # print("Shorts:")
  # print(num_shorts)
  # print("Buybacks:")
  # print(num_buybacks)

  gain=netassets-oc_potential_gains
  differences=c(differences,gain)
  percent.adv=gain/oc_potential_gains*100;
  advantage=c(advantage,percent.adv)
}
row=c(n,frac.n,mean(differences),mean(advantage))
diff.adv.df1=rbind(diff.adv.df1,row)

  }
}
diff.adv.df1=diff.adv.df1[-1,]

#-----------------------------------------------------------------------------
```


```{r visualisation short,fig.width=8,fig.height=5}
#SHORTING INVESTMENT STRATEGY VISUALIZATION CODE
#-----------------------------------------------------------------------------
#initial parameters that are set or given a range of values to loop over
bestp.parameters=bestp(perf_logistic,"Logistic")
p=as.numeric(bestp.parameters[1]) #probability threshold
modeltype=bestp.parameters[2]
sd=0 #initialize SD
#num stocks allowed to be bought/sold in investment strategy
n=180
#multiple of num stucks allowed to be bought/sold in case of strong prediction
frac.n=4
margin = 0
#based on data$Date column
start.time=1501
forecast=240
end.time=start.time+forecast
main=paste("Shorting Sim. w/ ",modeltype," Model ",toString(actualDates[start.time]),
  " to ",toString(actualDates[end.time]))

#get actual index of start.time
start=which(start.time==data$Date)

num_shorts = 0;
num_buybacks = 0
init.stocks=1000
bank=init.stocks*data$real_price[which(start.time==data$Date)]/100

#start by not shorting
num_stocks = 0;
owed_stock=0

bank_series = c(bank)
owed_stock_value=c(owed_stock)
total_assets=init.stocks*data$real_price[which(start.time==data$Date)]/100
num_stocks_series = c(num_stocks)
normal_assets = init.stocks*data$real_price[which(start.time==data$Date)]/100
#track predicted increase/decrease over time
predictions=data_frame(index=numeric(1),date=numeric(1),prediction=character(1))
  
for(i in start.time:(end.time-1)){
  j=which(i==data$Date)
  
  if(modeltype=="KNN"){
  # for knn (updated model each iteration based on previous data)
  pred.prob=knn(train = data[1:(j-1),-ncol(data)],
                test = data[j,-ncol(data)],
                cl = data$monthly_price_change_dir[1:(j-1)],
                k = bestk.knn, prob=TRUE)
  pred.prob=attr(pred.prob, "prob")
  }
  if(modeltype=="Logistic"){
  #for logistic (updated model each iteration based on previous data)
  log.reg = glm(monthly_price_change_dir~.,data=data[1:(j-1),], family=binomial)
  pred.prob=predict(log.reg, data[j,], type="response")
  }
  
  pred.change=ifelse(pred.prob>p,"Increase","Decrease")
  stocks.value=n*data$real_price[j]/100
  next.percent.change=(data$real_price[j+1]-data$real_price[j])/data$real_price[j]
  
  #if model predicts increase and we have enough money to buy n more stocks
  if(pred.change=="Increase" && bank>=stocks.value && num_stocks<=-n){
    bank=bank-stocks.value #buy n stocks
    num_stocks=num_stocks + n;
    num_buybacks = num_buybacks+1;
  }
  #if model predicts decrease and we have enough stock value we sell n stocks
  if(pred.change=="Decrease" && bank>=margin*stocks.value){
    num_stocks=num_stocks-n #sell n stocks
    bank=bank+stocks.value
    num_shorts = num_shorts+1
  
 
  }
  owed_stock=num_stocks*data$real_price[j]/100
  
  bank_series = c(bank_series,bank)
  num_stocks_series = c(num_stocks_series,num_stocks)
  owed_stock_value= c(owed_stock_value,owed_stock)
  total_assets= c(total_assets,bank+owed_stock)
  normal_assets = c(normal_assets,data$real_price[j]*init.stocks/100)
  
  predictions = rbind(predictions,c(j,i,pred.change))
  
}

owed_stock_value=-owed_stock_value
netassets=bank+num_stocks*data$real_price[which(end.time==data$Date)]/100
total_assets[forecast+1]=netassets
print("netassets")
print(netassets)
#without buying and selling
stock.value.normal=init.stocks*data$real_price[which(end.time==data$Date)]/100
normal_assets=c(normal_assets,stock.value.normal)
print("stock.value.normal")
print(stock.value.normal)
gain=netassets-stock.value.normal
percent.adv=round(gain/stock.value.normal,3)*100
print("percent.adv")
print(percent.adv)
print("start date")
actualDates[start.time]
print("end date")
actualDates[end.time]


max=max(normal_assets,total_assets,bank_series,owed_stock_value)+20000
min=min(normal_assets,total_assets,bank_series,owed_stock_value)-20000
range=max-min

if(modeltype=="Logistic"){
  plotstring=paste("n=",toString(n),
                   ", percent.adv=",toString(percent.adv),"%",
                   ", shorts=",toString(num_shorts),
                   ", buybacks=",toString(num_buybacks))
}
if(modeltype=="KNN"){
   plotstring=paste("n=",toString(n),
                   ", percent.adv=",toString(percent.adv),"%",
                   ", shorts=",toString(num_shorts),
                   ", buybacks=",toString(num_buybacks))
}

plot(1:(forecast+1),total_assets,col="red",
     ylim=c(min,max),
     ylab="Value ($)",xlab="Months",pch=1,
     main=main,cex=1,yaxt="n")
     #main="Long Position Sim. w/ ** Model for Dates")
points(normal_assets,col="blue",pch=6)
points(bank_series,col="orange",cex=.5,pch=3)
points(owed_stock_value,col="green",cex=.5,pch=3)
legend("topleft",
  	c("Total Assets","Normal","Bank","Assets Owed"),
  	fill=c("red","blue","orange","green"), 
  	cex=.8,horiz=TRUE,inset=.02)
text(forecast/2, (min+5000), plotstring, cex = .8)
axis(2,at=c(0,round(range/3,-3),round(range*2/3,-3)))
#abline(a=0,b=0,lty=2)

#-----------------------------------------------------------------------------
```

```{r }
print("around before/during dot com bubble burt")
print("actual burst 1551-1582")
#logistic predicts decrease dates 1544-1585
data[1410:1420,1:7] %>%
  apply(2,mean)
#log predicts decrease
data[1421:1430,1:7] %>%
  apply(2,mean)

print("arounds before/during recession")
print("actual recession 1642-1659")
#log predicts decrease dates 1642-1666
data[1511:1521,1:7] %>%
  apply(2,mean)
#log predicts decrease
data[1522:1532,1:7] %>%
  apply(2,mean)

plot(1:length(data$real_price),data$real_price)

```
